# ğŸ‡ LeetCode 49 â€” Group Anagrams | UMPIRE (English)

### ğŸ§  Understand

* **Input:** `strs: string[]` (e.g., `["eat","tea","tan","ate","nat","bat"]`)
* **Output:** `string[][]`, where each sub-array contains words that are mutual anagrams.
* **Order:** The order of groups and the order of words inside a group are *not* required to be stable unless specified.
* **Anagram definition:** Two words are anagrams iff they contain exactly the same letters with the same multiplicities (order-free).
* **Common constraints:** up to `10^4` words, each up to \~100 chars, lowercase aâ€“z.

#### âœ… Edge cases

* Empty string(s): `["",""] â†’ [["",""]]`
* Single item: `["a"] â†’ [["a"]]`
* Many duplicates: `["a","a","a"] â†’ [["a","a","a"]]`
* Very long strings: consider time cost of per-string sorting.

<br>


### ğŸ§² Match

* **Pattern:** Hashing by a **canonical signature** so that anagrams share the same key.
* **Two mainstream signatures:**

  1. **Sorted string** â€” key is `''.join(sorted(s))` (simple; `O(L log L)` per word).
  2. **26-letter frequency vector** â€” key is `tuple(counts)` for `'a'..'z'` (faster; `O(L)` per word).

<br>


### ğŸ—ºï¸ Plan

* **Plan A (Sorted key):**

  1. For each word `s`, compute `key = ''.join(sorted(s))`.
  2. Push `s` into `groups[key]`.
  3. Return `groups.values()`.

* **Plan B (26-count key):**

  1. For each `s`, build `counts[26]` by `counts[ord(ch)-ord('a')]++`.
  2. Convert to immutable key with `tuple(counts)`.
  3. Group by this key and return values.

* **Complexities:**

  * Plan A: `O(N * L log L)` time; `O(N * L)` space.
  * Plan B: `O(N * L)` time; `O(N * L)` space (keys are fixed-length).

<br>


### ğŸ› ï¸ Implement

#### ğŸ Python â€” Plan A (sorted key, simplest)

```python
from collections import defaultdict
from typing import List

class Solution:
    def groupAnagrams(self, strs: List[str]) -> List[List[str]]:
        # Map: signature -> list of original words
        groups = defaultdict(list)

        for s in strs:
            # 1) Canonical signature by sorting characters
            #    Sorting ensures anagrams map to the same key, e.g. "eat","tea","ate" -> "aet"
            key = ''.join(sorted(s))  # O(L log L)

            # 2) Append this word into its group bucket
            groups[key].append(s)

        # 3) Return the grouped anagrams (order does not matter)
        return list(groups.values())
```

#### ğŸ² Python â€” Plan B (26-letter frequency key, faster)

```python
from collections import defaultdict
from typing import List

class Solution:
    def groupAnagrams(self, strs: List[str]) -> List[List[str]]:
        groups = defaultdict(list)  # key: 26-length tuple -> list of words

        for s in strs:
            # 1) Build 26-length frequency vector for 'a'..'z'
            counts = [0] * 26
            for ch in s:
                # Assumes lowercase a..z per problem statement
                idx = ord(ch) - ord('a')
                counts[idx] += 1   # O(L) total over the word

            # 2) Convert to immutable tuple so it can be used as a dict key
            key = tuple(counts)

            # 3) Bucket this word under its frequency-signature
            groups[key].append(s)

        return list(groups.values())
```

#### âš¡ JavaScript â€” Plan A (sorted key)

```javascript
/**
 * @param {string[]} strs
 * @return {string[][]}
 */
function groupAnagrams(strs) {
  // Map: signature -> string[]
  const groups = new Map();

  for (const s of strs) {
    // 1) Sort characters to get a canonical signature
    //    Using spread handles Unicode code points better than split("")
    const key = [...s].sort().join(""); // O(L log L)

    // 2) Push into bucket
    if (!groups.has(key)) groups.set(key, []);
    groups.get(key).push(s);
  }

  // 3) Materialize values into an array of arrays
  return Array.from(groups.values());
}
```

#### ğŸš€ JavaScript â€” Plan B (26-letter frequency key)

```javascript
/**
 * @param {string[]} strs
 * @return {string[][]}
 */
function groupAnagrams(strs) {
  const groups = new Map(); // key: serialized frequency -> string[]

  for (const s of strs) {
    // 1) Build 26-length frequency array
    const counts = new Array(26).fill(0);
    for (let i = 0; i < s.length; i++) {
      const idx = s.charCodeAt(i) - 97; // 'a' -> 97
      counts[idx] += 1;                  // O(L)
    }

    // 2) Serialize with a delimiter to avoid ambiguity, e.g., "1#11" != "11#1"
    const key = counts.join("#");

    // 3) Bucket this word
    if (!groups.has(key)) groups.set(key, []);
    groups.get(key).push(s);
  }

  return Array.from(groups.values());
}
```

<br>


### ğŸ” Review

**Walkthrough with** `["eat","tea","tan","ate","nat","bat"]` (sorted key):

* `"eat" -> "aet"` â†’ `{"aet": ["eat"]}`
* `"tea" -> "aet"` â†’ `{"aet": ["eat","tea"]}`
* `"tan" -> "ant"` â†’ `{"aet": [...], "ant": ["tan"]}`
* `"ate" -> "aet"` â†’ `{"aet": ["eat","tea","ate"], "ant": ["tan"]}`
* `"nat" -> "ant"` â†’ `{"aet": [...], "ant": ["tan","nat"]}`
* `"bat" -> "abt"` â†’ `{"aet": [...], "ant": [...], "abt": ["bat"]}`

One valid output: `[["eat","tea","ate"],["tan","nat"],["bat"]]` (order agnostic).

<br>


### ğŸ“ˆ Evaluate

* **Correctness:** Anagrams share identical sorted forms or identical per-letter counts; both signatures are complete invariants.
* **Time/Space:**

  * Plan A: `O(N * L log L)` / `O(N * L)`
  * Plan B: `O(N * L)` / `O(N * L)`
* **Trade-offs:** Sorted key is easiest to write; count key scales better for long words or large inputs.

<br>


# ğŸ‘ LeetCode 49 â€” å­—æ¯ç•°ä½è©åˆ†çµ„ | UMPIREï¼ˆä¸­æ–‡ï¼‰

### ğŸ§© ç†è§£ï¼ˆUnderstandï¼‰

* **è¼¸å…¥ï¼š** `strs: string[]`ï¼ˆå¦‚ `["eat","tea","tan","ate","nat","bat"]`ï¼‰
* **è¼¸å‡ºï¼š** `string[][]`ï¼Œæ¯å€‹å­é™£åˆ—æ˜¯ä¸€çµ„ç•°ä½è©ã€‚
* **é †åºï¼š** ç¾¤çµ„èˆ‡ç¾¤çµ„å…§çš„é †åºé€šå¸¸ä¸è¦æ±‚å›ºå®šã€‚
* **ç•°ä½è©å®šç¾©ï¼š** å…©å­—ä¸²å«**ç›¸åŒå­—æ¯èˆ‡ç›¸åŒæ¬¡æ•¸**ï¼ˆé †åºç„¡é—œï¼‰ã€‚
* **å¸¸è¦‹é™åˆ¶ï¼š** æœ€å¤š `10^4` å€‹å­—ï¼Œå–®å­—é•·åº¦è‡³å¤šç´„ 100ï¼Œçš†ç‚ºå°å¯«è‹±æ–‡å­—æ¯ã€‚

#### âœ… é‚Šç•Œæ¡ˆä¾‹

* ç©ºå­—ä¸²ï¼š`["",""] â†’ [["",""]]`
* å–®ä¸€å…ƒç´ ï¼š`["a"] â†’ [["a"]]`
* å¤§é‡é‡è¤‡ï¼š`["a","a","a"] â†’ [["a","a","a"]]`
* æ¥µé•·å­—ä¸²ï¼šæ³¨æ„æ’åºæˆæœ¬ã€‚

<br>


### ğŸ”— åŒ¹é…ï¼ˆMatchï¼‰

* **æ ¸å¿ƒæ¨¡å¼ï¼š** ä½¿ç”¨**æ¨™æº–åŒ–ç°½å**åšé›œæ¹Šåˆ†çµ„ï¼Œè®“ç•°ä½è©å…±äº«åŒä¸€æŠŠ keyã€‚
* **å…©å¤§ç°½åæ³•ï¼š**

  1. **æ’åºå­—ä¸²éµ**ï¼š`''.join(sorted(s))`ï¼ˆç›´è§€ï¼›æ¯å­— `O(L log L)`ï¼‰ã€‚
  2. **26 ç¶­è¨ˆæ•¸éµ**ï¼š`tuple(counts)`ï¼ˆè¼ƒå¿«ï¼›æ¯å­— `O(L)`ï¼‰ã€‚

<br>


### ğŸ“ è¦åŠƒï¼ˆPlanï¼‰

* **æ–¹æ¡ˆ Aï¼ˆæ’åºéµï¼‰ï¼š**

  1. å°æ¯å€‹ `s` è¨ˆç®— `key = ''.join(sorted(s))`ã€‚
  2. å°‡ `s` æ”¾å…¥ `groups[key]`ã€‚
  3. å›å‚³ `groups.values()`ã€‚

* **æ–¹æ¡ˆ Bï¼ˆ26 è¨ˆæ•¸éµï¼‰ï¼š**

  1. å°æ¯å€‹ `s` å»ºç«‹ `counts[26]`ï¼Œ`counts[ord(ch)-ord('a')]++`ã€‚
  2. ç”¨ `tuple(counts)` è½‰æˆä¸å¯è®Šéµã€‚
  3. ä¾æ­¤éµåˆ†çµ„ä¸¦å›å‚³å€¼ã€‚

* **è¤‡é›œåº¦ï¼š**

  * æ–¹æ¡ˆ Aï¼šæ™‚é–“ `O(N * L log L)`ï¼›ç©ºé–“ `O(N * L)`ã€‚
  * æ–¹æ¡ˆ Bï¼šæ™‚é–“ `O(N * L)`ï¼›ç©ºé–“ `O(N * L)`ï¼ˆéµé•·å›ºå®šï¼‰ã€‚

<br>


### ğŸ§ª å¯¦ä½œï¼ˆImplementï¼‰

#### ğŸ¼ Python â€” æ–¹æ¡ˆ Aï¼ˆæ’åºéµï¼Œæœ€æ˜“ä¸Šæ‰‹ï¼‰

```python
from collections import defaultdict
from typing import List

class Solution:
    def groupAnagrams(self, strs: List[str]) -> List[List[str]]:
        # ç°½åï¼ˆæ’åºå­—ä¸²ï¼‰ -> è©²çµ„çš„åŸå­—ä¸²æ¸…å–®
        groups = defaultdict(list)

        for s in strs:
            # 1) ä»¥æ’åºå­—å…ƒä½œç‚ºæ¨™æº–åŒ–ç°½å
            #    ä¾‹å¦‚ "eat","tea","ate" çš†æœƒè®Šæˆ "aet"
            key = ''.join(sorted(s))  # æ¯å­— O(L log L)

            # 2) ä¸Ÿå…¥å°æ‡‰çš„æ¡¶å­
            groups[key].append(s)

        # 3) å›å‚³æ‰€æœ‰æ¡¶å­å…§å®¹ï¼ˆé †åºä¸é‡è¦ï¼‰
        return list(groups.values())
```

#### ğŸ§ Python â€” æ–¹æ¡ˆ Bï¼ˆ26 è¨ˆæ•¸éµï¼Œæ•ˆèƒ½æ›´ä½³ï¼‰

```python
from collections import defaultdict
from typing import List

class Solution:
    def groupAnagrams(self, strs: List[str]) -> List[List[str]]:
        groups = defaultdict(list)  # key: 26 é•·åº¦ tuple -> è©²çµ„å­—ä¸²

        for s in strs:
            # 1) å»ºç«‹ a..z çš„æ¬¡æ•¸é™£åˆ—
            counts = [0] * 26
            for ch in s:
                idx = ord(ch) - ord('a')  # é¡Œç›®å‡è¨­è¼¸å…¥ç‚ºå°å¯«
                counts[idx] += 1          # æ¯å­— O(L)

            # 2) è½‰ç‚ºä¸å¯è®Š tupleï¼Œæ‰èƒ½ç•¶ä½œ dict çš„éµ
            key = tuple(counts)

            # 3) ä¾ç°½ååˆ†çµ„
            groups[key].append(s)

        return list(groups.values())
```

#### ğŸ¦Š JavaScript â€” æ–¹æ¡ˆ Aï¼ˆæ’åºéµï¼‰

```javascript
/**
 * @param {string[]} strs
 * @return {string[][]}
 */
function groupAnagrams(strs) {
  const groups = new Map(); // ç°½å -> é™£åˆ—

  for (const s of strs) {
    // 1) æ’åºå­—å…ƒæˆç‚ºæ¨™æº–åŒ–ç°½å
    const key = [...s].sort().join(""); // æ¯å­— O(L log L)

    // 2) åŠ å…¥æ¡¶å­
    if (!groups.has(key)) groups.set(key, []);
    groups.get(key).push(s);
  }

  return Array.from(groups.values());
}
```

#### ğŸ¯ JavaScript â€” æ–¹æ¡ˆ Bï¼ˆ26 è¨ˆæ•¸éµï¼‰

```javascript
/**
 * @param {string[]} strs
 * @return {string[][]}
 */
function groupAnagrams(strs) {
  const groups = new Map(); // key: è¨ˆæ•¸åºåˆ—åŒ–å­—ä¸² -> é™£åˆ—

  for (const s of strs) {
    // 1) çµ±è¨ˆ a..z æ¬¡æ•¸
    const counts = new Array(26).fill(0);
    for (let i = 0; i < s.length; i++) {
      const idx = s.charCodeAt(i) - 97; // 'a' çš„ ASCII ç‚º 97
      counts[idx] += 1;                  // æ¯å­— O(L)
    }

    // 2) ç”¨åˆ†éš”ç¬¦åºåˆ—åŒ–ï¼Œé¿å…æ­§ç¾©
    const key = counts.join("#");

    // 3) ä¾éµåˆ†çµ„
    if (!groups.has(key)) groups.set(key, []);
    groups.get(key).push(s);
  }

  return Array.from(groups.values());
}
```

<br>


### ğŸª æª¢æŸ¥ï¼ˆReviewï¼‰

ä»¥ `["eat","tea","tan","ate","nat","bat"]` ç‚ºä¾‹ï¼ˆæ’åºéµï¼‰ï¼š

* `"eat" -> "aet"`ï¼š`{"aet": ["eat"]}`
* `"tea" -> "aet"`ï¼š`{"aet": ["eat","tea"]}`
* `"tan" -> "ant"`ï¼š`{"aet": [...], "ant": ["tan"]}`
* `"ate" -> "aet"`ï¼š`{"aet": ["eat","tea","ate"], "ant": ["tan"]}`
* `"nat" -> "ant"`ï¼š`{"aet": [...], "ant": ["tan","nat"]}`
* `"bat" -> "abt"`ï¼š`{"aet": [...], "ant": [...], "abt": ["bat"]}`

å¯æ¥å—è¼¸å‡ºï¼š`[["eat","tea","ate"],["tan","nat"],["bat"]]`ï¼ˆé †åºç„¡è¦æ±‚ï¼‰ã€‚

<br>


### ğŸ§® è©•ä¼°ï¼ˆEvaluateï¼‰

* **æ­£ç¢ºæ€§ï¼š** æ’åºæˆ–è¨ˆæ•¸çš†ç‚ºå®Œæ•´ç°½åï¼›åŒç°½åå³åŒçµ„ç•°ä½è©ã€‚
* **æ™‚é–“/ç©ºé–“ï¼š**

  * æ–¹æ¡ˆ Aï¼š`O(N * L log L)` / `O(N * L)`
  * æ–¹æ¡ˆ Bï¼š`O(N * L)` / `O(N * L)`
* **å–æ¨ï¼š** æ–¹æ¡ˆ A æœ€ç›´è§€ã€ç¢¼é‡å°‘ï¼›æ–¹æ¡ˆ B è¼ƒå¿«ã€é©åˆé•·å­—ä¸²æˆ–å¤§è³‡æ–™é‡ã€‚

<br>

# ğŸ“Œ Additional Notes â€” Writing This Problem Well

### ğŸ Pitfalls & Gotchas

* **Donâ€™t use a mutable list as a dict keyï¼ˆPythonï¼‰**ï¼š`list` ä¸å¯é›œæ¹Šï¼›è«‹ç”¨ `tuple(counts)`ã€‚
* **String serialization ambiguityï¼ˆJSï¼‰**ï¼šåºåˆ—åŒ–è¨ˆæ•¸æ™‚è«‹åŠ åˆ†éš”ç¬¦ï¼ˆå¦‚ `'#'`ï¼‰ï¼Œé¿å… `"111"` çš„æ­§ç¾©ã€‚
* **Input normalization**ï¼šè‹¥é¡Œç›®å¯èƒ½å«å¤§å¯«æˆ–éå­—æ¯ï¼Œå…ˆæ­£è¦åŒ–ï¼ˆ`lower()`ã€éæ¿¾ `isalpha()`ï¼‰å†å»ºç°½åï¼›æˆ–ç”¨ `Counter(s)` ä¸¦å°‡ `sorted(counter.items())` è®Šæˆ `tuple` ç•¶éµã€‚
* **Performance choice**ï¼šé•·å­—ä¸²/å¤§ N â†’ å„ªå…ˆç”¨è¨ˆæ•¸éµï¼›ä¸€èˆ¬æƒ…å¢ƒç”¨æ’åºéµå³å¯ã€‚
* **Deterministic output**ï¼šè‹¥é¢è©¦å®˜è¦æ±‚çµ„å…§æ’åºï¼Œæœ€å¾Œå°æ¯çµ„ `sort()`ï¼ˆé¡å¤– `O(total * log groupSize)`ï¼‰ã€‚

### ğŸŒ± Variations & Follow-ups

* **Case-insensitive / ignore spaces & punctuation**ï¼šå…ˆæ­£è¦åŒ–å­—ä¸²å†ç°½åã€‚
* **Unicode / multilingual**ï¼šä½¿ç”¨å­—å…ƒâ†’æ¬¡æ•¸çš„ `Counter/Map`ï¼Œç°½åç‚º `tuple(sorted(counter.items()))`ã€‚
* **Streaming / huge input**ï¼šä¾ç°½åå‰ç¶´åˆ†æ¡¶ï¼ˆå¤–éƒ¨å­˜å„²ï¼‰ï¼Œæœ€å¾Œåˆä½µã€‚
* **Parallelization**ï¼šç°½åè¨ˆç®—å¯ä¸¦è¡Œï¼Œæœ€å¾Œ reduce by keyã€‚

### ğŸ§« Mini Test Cases

* `[""] â†’ [[""]]`
* `["",""] â†’ [["",""]]`
* `["a"] â†’ [["a"]]`
* `["ab","ba","abc","cab","bca","cba"] â†’ [["ab","ba"],["abc","cab","bca","cba"]]`
* `["eat","Tea","ate!"]` after normalization (lower + letters only) â†’ `[["eat","tea","ate"]]`

### ğŸ—£ï¸ Quick Interview Script

> â€œIâ€™ll hash each word by a canonical signature so anagrams share the same key.
> The simplest signature is the sorted characters (`O(L log L)` per word).
> If performance matters for long words, Iâ€™ll use a 26-length frequency vector and convert it to an immutable key (`tuple` in Python) for `O(L)` per word.
> Then I group words in a hashmap keyed by the signature and return the values.
> Complexity is `O(NÂ·L log L)` or `O(NÂ·L)` depending on the signature; space is `O(NÂ·L)`.
> If needed, Iâ€™ll normalize case or strip non-letters, and sort each group for deterministic output.â€

<br>

# ğŸ¤ Full Spoken-Style Interview Answer 

### 1) Clarify the problem & read examples/constraints

**What Iâ€™d say:**

> â€œIâ€™ll restate the problem to make sure I understand it. Iâ€™m given an array of strings, and I need to group the anagrams together. Two strings are anagrams if they have exactly the same letters with the same counts, just in a different order.
>
> For example, if the input is `["eat","tea","tan","ate","nat","bat"]`, one valid output is `[["eat","tea","ate"],["tan","nat"],["bat"]]`. The order of the groups and the order **inside** each group donâ€™t matter unless you specify otherwise.
>
> Iâ€™ll assume all strings are lowercase English letters `'a'..'z'`, lengths up to maybe 100, and the number of words can be up to, say, `10^4`. Please let me know if there are any constraints I should be aware of beyond this. If not, Iâ€™ll proceed with those typical constraints.â€

---

### 2) Discuss edge cases

**What Iâ€™d say:**

> â€œEdge cases Iâ€™ll keep in mind:
> â€¢ Empty strings: `["",""]` should group together.
> â€¢ Single element: `["a"]` returns `[["a"]]`.
> â€¢ Lots of duplicates: `["a","a","a"]` stays together.
> â€¢ Very long strings: I should be mindful of sorting costs per string.
> â€¢ Potential non-letters or mixed caseâ€”if that existed Iâ€™d normalize (e.g., lowercase and strip non-letters), but for this problem Iâ€™ll assume clean lowercase input.â€

---

### 3) Consider brute-force and optimal approach

**What Iâ€™d say:**

> â€œA brute-force way would be: for each string, compare it against every other string that hasnâ€™t been grouped yet, and check if theyâ€™re anagrams. A direct anagram check can be `O(L)` if I count letters, or `O(L log L)` if I sort each pair. But doing that for all pairs is `O(N^2 * L)`, which is too slow when `N` is large.
>
> A **much better** approach is to use a **hash map** where the key is a **canonical signature** of the wordâ€”an identifier thatâ€™s identical for all anagrams. There are two common signatures:
>
> â€¢ **Sorted string**: sort the characters; anagrams map to the same sorted result. Per word cost `O(L log L)`.
> â€¢ **26-letter frequency vector**: count a..z and use that 26-length count as the key; per word cost `O(L)`.
>
> Both are valid. If performance matters for long strings, the frequency vector is strictly better (`O(NÂ·L)` overall). For simplicity under time pressure, the sorted key is very fast to code and is usually accepted. Iâ€™ll code the **frequency-vector version** as the optimal one, and I can also show the sorted-key version if youâ€™d like.â€

---

### 4) Explain & implement the optimal code (talk while typing)

**What Iâ€™d say while coding (Python, frequency-vector key):**

> â€œIâ€™ll write a function `groupAnagrams` that returns a list of groups. Iâ€™ll create a dictionary from signature to list of words. For each word, Iâ€™ll build a 26-length count array, convert it to a tuple to make it hashable, and then append the word to that bucket. Finally Iâ€™ll return the dictionary values.â€

```python
from collections import defaultdict
from typing import List

class Solution:
    def groupAnagrams(self, strs: List[str]) -> List[List[str]]:
        # groups maps: frequency signature (tuple of 26 ints) -> list of original words
        groups = defaultdict(list)

        for s in strs:
            # Build a 26-length frequency vector for 'a'..'z'.
            # This is O(L) per word where L is the length of s.
            freq = [0] * 26
            for ch in s:
                # Assuming lowercase 'a'..'z'.
                # Map 'a'->0, 'b'->1, ..., 'z'->25
                freq[ord(ch) - ord('a')] += 1

            # Convert list to tuple so it's immutable and hashable as a dict key.
            signature = tuple(freq)

            # Append the original string to its anagram bucket.
            groups[signature].append(s)

        # The values of the dict are the grouped anagrams.
        return list(groups.values())
```

**How Iâ€™d quickly walk through the example out loud:**

> â€œFor `eat`, the counts are a:1, e:1, t:1 â†’ same signature as `tea` and `ate`, so they land in the same bucket. For `tan` and `nat`, counts match and they share a bucket. `bat` lands in its own bucket. At the end I return all the buckets as a list of lists.â€

**(Optional) If interviewer asks for the simpler sorted-key version:**

> â€œHereâ€™s the concise sorted-key solution. Itâ€™s a tiny bit slower on long strings (`O(L log L)` per word) but often totally fine.â€

```python
from collections import defaultdict
from typing import List

class SolutionSortedKey:
    def groupAnagrams(self, strs: List[str]) -> List[List[str]]:
        groups = defaultdict(list)
        for s in strs:
            # Canonical signature by sorting characters.
            # "eat","tea","ate" -> "aet"
            key = ''.join(sorted(s))  # O(L log L)
            groups[key].append(s)
        return list(groups.values())
```

---

### 5) Discuss time/space complexity

**What Iâ€™d say:**

> â€œFor the frequency-vector solution:
> â€¢ Time complexity is **O(N Â· L)**: each word is processed once and we count characters in linear time.
> â€¢ Space complexity is **O(N Â· L)** overall because we store all the input strings in the output structure; the keys themselves are fixed size (26 integers) per *distinct* group but thatâ€™s relatively small compared to the total characters stored.
>
> For the sorted-key approach:
> â€¢ Time is **O(N Â· L log L)** due to sorting each word.
> â€¢ Space is **O(N Â· L)** as well.â€

---

### 6) Mention follow-up questions

**What Iâ€™d say:**

> â€œA few natural follow-ups:
>
> 1. **Deterministic order**: If you want each group sorted, I can sort each bucket at the end. If you want the buckets in a specific order, we can sort by, say, the first word or by group size.
> 2. **Mixed case or punctuation**: If inputs may contain capitals or non-letters, Iâ€™d normalizeâ€”lowercase and optionally filter to lettersâ€”before building the signature.
> 3. **Unicode / multilingual**: For arbitrary character sets, Iâ€™d use a `collections.Counter` of characters and make the key a `tuple(sorted(counter.items()))`. Thatâ€™s still `O(L)` per word but with a slightly larger constant.
> 4. **Streaming / huge data**: If memory is tight, we could hash to temporary files by signature prefix and merge later (external grouping).
> 5. **Parallelization**: Signature building is embarrassingly parallel; a map-reduce pattern works wellâ€”map words to signatures, then reduce by key.â€

---

### Bonus: â€œWhat I literally say while typingâ€ (condensed)

> â€œIâ€™ll use a hash map from a canonical signature to the list of words. For optimal time Iâ€™ll build a 26-length frequency vector per word, convert it to a tuple, and use that as the key. Anagrams share the same letter counts, so they end up in the same bucket. Time is `O(NÂ·L)`, space is `O(NÂ·L)`. If you prefer simpler code, I can switch to sorting each word and using the sorted string as the key; thatâ€™s `O(NÂ·L log L)` but shorter to write. Iâ€™ll go with the frequency vector now and then dry-run the provided example to confirm correctness.â€

<br>


# ğŸ¯ Real-World Applicationsï½œå¯¦éš›æ‡‰ç”¨å ´æ™¯


### ğŸ—ƒï¸ Grouping Log Entries by Structure

#### åˆ†çµ„å…·æœ‰ç›¸åŒçµæ§‹çš„æ—¥èªŒè¨Šæ¯

**EN:**
In large-scale systems, log entries often have different parameter values but follow the same template (like: `"User 123 logged in"` vs `"User 456 logged in"`).
We can normalize the logs (by removing user IDs, timestamps, etc.) and group them by the template (signature). This is similar to grouping by anagram keys.

**ä¸­æ–‡ï¼š**
åœ¨å¤§å‹ç³»çµ±ä¸­ï¼Œæ—¥èªŒè¨Šæ¯é›–ç„¶åƒæ•¸ä¸åŒï¼Œä½†çµæ§‹å¾ˆé¡ä¼¼ï¼ˆä¾‹å¦‚ `"User 123 logged in"` è·Ÿ `"User 456 logged in"`ï¼‰ã€‚
æˆ‘å€‘å¯ä»¥å»é™¤å¯è®Šè³‡è¨Šï¼ˆåƒä½¿ç”¨è€… IDã€æ™‚é–“æˆ³ï¼‰å¾Œåšç°½ååŒ–ï¼Œå°‡å…·æœ‰ç›¸åŒã€Œçµæ§‹ã€çš„æ—¥èªŒåˆ†çµ„ï¼Œé€™å°±åƒæ˜¯ç•°ä½è©åˆ†çµ„çš„æ¦‚å¿µã€‚

---

### ğŸ” Detecting Plagiarism or Code Similarity

#### åµæ¸¬æŠ„è¥²æˆ–ç¨‹å¼ç¢¼çµæ§‹ç›¸ä¼¼æ€§

**EN:**
In education or software engineering, you might want to detect if two pieces of code or two documents have the same underlying structure.
You can strip out variable names or formatting and group submissions with identical normalized structure.

**ä¸­æ–‡ï¼š**
åœ¨æ•™è‚²æˆ–é–‹ç™¼ä¸­ï¼Œæˆ‘å€‘å¸¸æƒ³æª¢æŸ¥å…©ä»½ç¨‹å¼ç¢¼æˆ–æ–‡ä»¶æ˜¯å¦ã€Œæœ¬è³ªä¸Šã€ä¸€æ¨£ã€‚
å¯ä»¥å°‡è®Šæ•¸åç¨±æˆ–æ’ç‰ˆæ¸…é™¤ï¼Œä¿ç•™é‚è¼¯çµæ§‹å¾Œï¼Œå†ä»¥ç°½åæ–¹å¼åˆ†çµ„ï¼Œå°±åƒæ‰¾ç•°ä½è©é‚£æ¨£æ‰¾åˆ°çµæ§‹é›·åŒçš„ç¨‹å¼ã€‚

---

### ğŸ§¬ Grouping DNA Sequences with Same Composition

#### å°‡å…·æœ‰ç›¸åŒçµ„æˆçš„ DNA åºåˆ—æ­¸é¡

**EN:**
In bioinformatics, two DNA strands with the same base composition but different orders can be functionally relevant.
We can use the same technique: count base occurrences (`A`, `T`, `G`, `C`) and group sequences with identical counts.

**ä¸­æ–‡ï¼š**
åœ¨ç”Ÿç‰©è³‡è¨Šå­¸ä¸­ï¼Œæœ‰äº› DNA åºåˆ—é›–ç„¶é †åºä¸åŒï¼Œä½†å› ç‚ºå«æœ‰ä¸€æ¨£çš„ A/T/G/C æ•¸é‡ï¼Œå…·æœ‰é¡ä¼¼åŠŸèƒ½ã€‚
å¯ä»¥ç”¨é¡ä¼¼ç•°ä½è©çš„ã€Œè¨ˆæ•¸æ³•ã€ä¾†åˆ†çµ„é€™äº›åºåˆ—ï¼Œæ‰¾å‡ºæ½›åœ¨é—œè¯ã€‚

---

### ğŸ’¬ Grouping Synonyms or Translations with Same Letters

#### å°‡åŒå­—æ¯ä½†é †åºä¸åŒçš„è©å½™æˆ–ç¿»è­¯åˆ†åœ¨ä¸€èµ·

**EN:**
In natural language processing, some tools might group translations or misspellings based on character-level similarityâ€”anagram-like logic helps cluster words that are likely variants of each other.

**ä¸­æ–‡ï¼š**
åœ¨è‡ªç„¶èªè¨€è™•ç†ä¸­ï¼Œåƒæ‹¼å­—éŒ¯èª¤æˆ–åŒç¾©è©ï¼Œæœ‰æ™‚å­—æ¯ç›¸ä¼¼ä½†é †åºä¸åŒã€‚æˆ‘å€‘å¯ä»¥ç”¨ç•°ä½è©åˆ†çµ„æ³•ï¼Œå°‡é€™äº›ã€Œå¯èƒ½ç›¸é—œã€çš„å­—å½™æ­¸åœ¨ä¸€èµ·ï¼Œæå‡åˆ†ææº–ç¢ºåº¦ã€‚

---

### ğŸ“¦ Inventory or Recipe Matching

#### åº«å­˜æˆ–é£Ÿè­œææ–™çµ„åˆæ¯”å°

**EN:**
In supply chain or cooking apps, you may need to match combinations of ingredients or components, regardless of order.
Using a frequency-count signature of item quantities allows grouping interchangeable sets.

**ä¸­æ–‡ï¼š**
åœ¨ä¾›æ‡‰éˆæˆ–é£Ÿè­œæ‡‰ç”¨ä¸­ï¼Œææ–™çš„é †åºä¸é‡è¦ï¼Œåªè¦çµ„æˆç›¸åŒå°±å¯ä»¥äº’æ›ã€‚
åˆ©ç”¨é¡ä¼¼ç•°ä½è©çš„è¨ˆæ•¸ç°½åï¼Œå°±èƒ½æŠŠé€™äº›ææ–™çµ„åˆæ­£ç¢ºæ­¸ç‚ºåŒä¸€é¡ã€‚

---

### ğŸ” Cache De-duplication or Memoization

#### å¿«å–å»é‡æˆ–å‡½å¼è¨˜æ†¶åŒ–ï¼ˆMemoizationï¼‰

**EN:**
When using memoization, sometimes the order of inputs doesnâ€™t matter. For example, a function that takes a list of items as a set.
We can sort or normalize the input to avoid recomputing the same logic, just like using a sorted string key in anagram grouping.

**ä¸­æ–‡ï¼š**
åœ¨ä½¿ç”¨å¿«å–æˆ–å‡½å¼è¨˜æ†¶åŒ–æ™‚ï¼Œæœ‰äº›è¼¸å…¥é †åºä¸é‡è¦ï¼ˆå¦‚ä¸€çµ„é …ç›®é›†åˆï¼‰ã€‚
å¯ä»¥å…ˆæ’åºè¼¸å…¥ä¸¦åšç‚º keyï¼Œé€™æ¨£å°±èƒ½é¿å…é‡è¤‡è¨ˆç®—ï¼Œé€™å’Œç•°ä½è©çš„æ’åºç°½åæ³•æ˜¯ä¸€æ¨£çš„æ ¸å¿ƒæŠ€å·§ã€‚

